--- 
layout: post
date: 2022-03-23 03:00:00 AM
title: "Boostcamp AI Tech 3기 이미지 분류 대회 후기"
toc: true
toc_sticky: true
comments: true
categories: [NAVER BoostCamp AI Tech]
tags: [NAVER BoostCamp AI Tech]
---

> [Repository Link](https://github.com/boostcampaitech3/level1-image-classification-level1-recsys-15)

## 대회 목표 
- 모델의 성능 개선
- 효율 좋은 dataset, model, loss…etc 코드 작성

## 고민해본 문제들
- Task 분해에 대한 고민<br>
    해당 문제는 독립적으로는 18개의 class를 분류하는 문제이지만, Age, Gender, Mask 각각에 대한 분류 문제로 생각할 수 있다.<br>
    하지만, 독립적인 18개 분류 문제로 접근해도 그 수가 많지 않으므로 충분히 모델이 잘 분류할 것으로 기대할 수 있고 이에 따른 성능 비교가 필요하다.<br>
    또한, 한 개 모델이 3가지를 한번에 분류하는 경우와 각각의 모델이 Task에 대해 분류하는 경우에 대한 비교 역시 필요하다.<br>
- 불균형 처리에 대한 고민 <br>
    나이브하게 생각하였을 때, 불균형를 해결해 주는 방법을 통해 모델의 성능 개선을 꾀할 수 있을 것이다.<br>
    하지만, 가장 큰 불균형을 보인 데이터는 나이에 대한 데이터였으며,  나이에 대한 3개 클래스 중 2개 클래스는 비슷한 충분한 숫자를 가지고 있었다.<br>
    이에 따라 오히려 충분히 학습시키면, 오히려 나머지 2개 클래스의 디시전 바운더리가 더 명확해져 데이터가 부족한 클래스도 잘 예측할 수 있으리라 생각하였다.<br>
- 데이터셋 일반화에 대한 고민
    이미지 데이터이므로, 다양한 Augumentaion을 덧붙여서 데이터셋을 더 일반화 시킬 수 있다.<br>
    하지만 사람의 이미지이기에 뒤집어진 이미지가 들어올 리 없으므로, Vertical Flip이 필요하지 않은 등 Augmentation의 수준에 대하여 고민해 볼 필요가 있었다.<br>
- custom loss에 대한 고민
    제공받은 baseline에는 cross entropy 뿐 아니라 focal loss, f1 loss, label smoothing loss 등 다양한 custom loss가 정의되어 있었다.<br>
    cross entropy loss를 줄이는 것은 정확도 개선에 확실히 도움이 되지만, 대회는 f1 점수를 이용해 채점하기에 이를 고려할 필요가 있었다.<br>
    또한, multi label classification 구현을 위해 전용 loss function을 구현할 필요가 있었다.<br>
- pretrained model의 parameter freeze에 대한 고민 - 일반화 성능 향상에 효과적일까?<br>
    분류문제로 미리 훈련된 모델을 파인튜닝하여 활용하기에 쉽게 모델을 학습시킬 수 있다.<br>
    하지만 분류 레이어 뿐만 아니라 다른 학습된 부분까지 학습시키면 굉장히 빠르게 오버피팅될 수 있으며 이는 일반화 성능에 좋지 않은 효과를 가져다 줄 수 있다.<br>
    이를 위해 처음부터 분류 레이어가 아닌 부분에 대하여 고정시키거나, 일정한 수준의 학습이 이루어 진 후에 이를 고정시키고 분류 레이어만 학습시키는 등의 방법을 고민해볼 수 있다.<br>

## 해결하지 못한 문제
- 오버피팅에 대한 제어<br>
    Train Set과 Valid Set을 구분하여 학습시켰지만, 어느정도 학습된 이후 학습 정확도와 검증 정확도의 갭이 발생하며 오버피팅되는 모습을 관찰할 수 있기를 기대하였다.<br>
    하지만 오히려 학습을 시킬수록 검증 정확도까지 100%에 가까워지는 모습만 관찰할 수 있었고, 결국 오버피팅문제는 대회 내내 전혀 관리하지 못했다.<br>
    분류 레이어에 Dropout을 추가하는 정도로는 해결되지 않았고, 사람을 기준으로 Train과 Valid Set을 구분하였으니, 사람 자체에 대한 치팅은 일어날 수 없는 상황이었다.<br>
    해당 문제의 원인으로는 같은 배경에서 찍힌 비슷한 성별/연령의 사람들이 많았기 때문으로 추정하고 있으며, 사람이 아닌 배경을 보고 성별/연령을 구분하는 오류를 일으킨 것으로 생각한다.<br>
    이를 해결하기 위해 이미지의 중간을 잘라내서 학습하는 형태로 배경의 영향력을 줄여보려 시도하였지만, 큰 효과를 얻진 못했다.<br>

## 시도하지 못한 것
- 다른 목적의 모델을 파인튜닝하여 활용<br>
    예를 들어, yolo를 fine-tuning하여 대회에 적용해 보고 싶었다.<br>
    단순 호기심으로 진행 해보고 싶었던 아이디어였지만, 시간이 부족하여 진행하지 못했다.<br>
    별개로, 2개 이상의 모델을 묶어서 분류를 해보는 형태는 구현해 보았지만, 좋은 성능을 보이지는 않았다.<br>
- 이미지 로딩 과정의 정교한 설계<br>
    이미지는 기본적으로 디스크에 저장되어 있으며, baseline에서는 디스크에서 그때 그때 읽어 feeding 시키는 형태로 구현되어 있었다.<br>
    이를 약간 개선하여 이미지를 메모리에 올린 후 feeding시키면 좀 더 빠르게 학습시킬 수 있을 것으로 생각하였지만, 디스크에서 그때 그때 읽어 feeding 시키는 것의 학습 시간 차이를 직접 느끼지 못했다.<br>
    하지만 이 과정에서 약간 안일하게 접근하여, 시간을 측정하는 코드를 추가하여 개선된 정도를 수치화하지 직접 이득을 비교해 보는 작업을 진행하지는 않았다.<br>
- 테스트 코드 작성
    Augmentation 코드를 작성하거나, dataset 관련 부분을 작성할 때, 테스트 코드를 작성하여 작성하면 개발 속도 및 좀 더 강건하고 효율적인 코드를 작성하는데 효과적으로 작용하였을 수 있을 것으로 생각되지만, 미처 작성하지 못했다.<br>

## 오피스아워 이후
상위권 팀에서는 모두 Swin Transformer를 사용한 모습을 확인할 수 있었다. 해당 모델의 특징에 대해 공부해 보고 싶다.
상위권의 두 팀은 background를 제거하는 방향으로 오버피팅 문제를 해결한 모습을 확인할 수 있었다. 다만 각기 segmentation과 detection의 다른 방법을 활용하였으며, 이 두가지 방법의 성능 차이를 눈으로 확인해 보아도 좋은 인사이트를 얻을 수 있을 것 같다.

## 차후 목표사항
 dataset을 작성하는 과정에서, 처음에는 선형적으로 메모리에 이미지를 하나씩 올리는 형태로 구현하였었는데, 이 때 너무 오랜 시간이 필요로 했다. 결국은 None으로 이미지 리스트를 초기화한 후 dataloader의 worker가 첫 에포크를 돌 때 채워 넣도록 구현하였는데, 이 역시 정교한 설계로 생각되지는 않아 아쉽다. worker의 작동 원리 파악하고 GIL 등 파이썬의 특징에 대해 좀 더 공부하여 활용할 수 있도록 정리해보려 한다.<br>
 실험과 공부도 좋지만, 협업 과정에 있어 약간 아쉬운 부분이 있었다. 특히 일부 모델을 작성하는 과정에서 전용 loss가 필요했던 부분 등이 협업을 방해했던 부분이라 생각한다. 이를 더 쉽게 공유할 수 있도록 컨벤션 개선 및 쉽게 문서화할 수 있도록 노션 및 슬랙을 좀 더 적극적으로 활용할 필요가 있음을 느꼈다.
