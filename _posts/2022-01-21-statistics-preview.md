---
layout: post
date: 2022-01-21 03:00:00 AM
title: "통계학 맛보기"
toc: true
toc_sticky: true
comments: true
categories: []
tags: []
---

## 통계적 모델링
- 적절한 가정 위에서 확률본포를 추정(inference)
- 모집단의 분포를 정확하게 알아낼 수 없음 -> `근사적으로 확률분포를 추정`
- 데이터와 `추정 방법의 불확실성을 고려`하여 `위험을 최소화`
- `모수적(parametric) 방법론` : 데이터가 특정 확률분포를 따른다고 가정 후 분포를 결정하는 모수를 추정
- `비모수적(nonparametric) 방법론` : 특정 확률분포를 가정하지 않고, 데이터에 따라 모델의 구조 및 개수가 유연하게 바뀜
- 가정을 하는지, 아닌지에 따라 부여됨

## 확률분포 가정
- 데이터를 생성하는 원리를 가장 먼저 고려
<table>
    <tr>
        <td>
        데이터 상태
        </td>
        <td>
        분포 예시
        </td>
    </tr>
    <tr>
        <td>
        0 또는 1
        </td>
        <td>
        베르누이 분포
        </td>
    </tr>
    <tr>
        <td>
        n개의 이산적인 값
        </td>
        <td>
        카테고리 분포
        </td>
    </tr>
    <tr>
        <td>
        [0,1]
        </td>
        <td>
        베타 분포
        </td>
    </tr>
    <tr>
        <td>
        0 이상의 값
        </td>
        <td>
        감마분포, 로그정규분포 등
        </td>
    </tr>
    <tr>
        <td>
        R(실수) 전체의 값
        </td>
        <td>
        정규분포, 라플라스분포 등
        </td>
    </tr>
</table>

## 모수 추정
- 표본평균, 표본표준편차(n-1) 등 활용
- 표집분포(sampling distribution) != 표본분포(sample distrubution)
- 표본평균의 확률분포(통계량의 확률분포) 정규분포를 따르지만, 포본의 확률분포는 정규분포를 따르지 않을 수 있다.

## 최대가능도 추정법
- 모수를 추정하는 적절한 통계량은 조금씩 달라짐(표본평균, 표본분산만 활용하는 것은 위험)
- 이론적으로 가장 가능성이 높은 모수를 추정하는 방법
- maximum likelihood estimation, MLE
- 가능도(likelihood) 함수 : 모수를 따르는 분포Θ 가 x를 관찰할 가능성(확률이라기 보단, Θ에 대한 대소비교를 위함)
- 데이터가 독립적으로 추출되었을 경우, 확률밀도함수는 확률질량함수의 곱으로 표현 가능
- 로그함수의 성질을 이용하여, 곱셈을 덧셈으로 `최적화` 가능
- 정확도 관점에서 컴퓨터로 연산 가능
- 연산량을 O(n<sup>2</sup>) 에서 O(n)으로 줄여줌
- 손실을 최소화하는 방향으로 경사하강법을 사용하므로, 음의 로그가능도(negative log-likehood)를 최적화
- MLE는 불편추정량을 보장하지 않음.

## 딥러닝에서 최대가능도 추정법
- 소프트맥스 벡터는 카테고리분포의 모수를 모델링
- 정답레이블 y를 관찰데이터로 이용
- 확률분포인 소프트맥스 벡터의 로그가능도를 최적화

## KL 발산
- 두 확률분포 사이의 거리를 계산할 때 이용
- 최대가능도 추정법은 KL 발산을 최소화하는 것과 같다.