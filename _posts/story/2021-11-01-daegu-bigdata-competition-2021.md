---
layout: post
date: 2021-11-01 03:00:00 AM
title: "대구 빅데이터 분석 경진대회 3회 후기"
toc: true
toc_sticky: true
comments: true
categories: [ 이야기 ]
tags: [ 회고 ]
---

> [제3회 대구 빅데이터 분석 경진대회](https://www.dip.or.kr/home/notice/boardRead.ubs?fboardcd=notice&fboardnum=5066)
<br>
> [Repository Link](https://github.com/SNMHZ/Personal_Macroeconomic_Sensitivity)

<br>

# 어떤 대회인가?

<left><img src="http://www.dip.or.kr/files/boardImage/notice/2021/04/26/20210426175826_iyokbwlt.jpg" width="50%" height="50%"></left>

대구광역시에서 진행하는 빅데이터 분석 경진대회이다.

올해로 3회째 진행하였으며, 점점 경진대회의 규모가 커지고 있는 느낌이다.

대구광역시와 대구은행이 주최하기 때문인지 __공공 또는 금융__ 두 부문 중 하나를 선택하여 참여할 수 있다.

금융분야는 금융과 관련된 주제를 진행해야 하며, __대구은행 고객데이터__ 를 필수로 활용해야 한다.

그리고 우리 팀은 금융분야로 참가하였다.

<br>

# 일정

<table>
    <tr>
        <td>
        내용
        </td>
        <td>
        날짜
        </td>
        <td>
        장소
        </td>
    </tr>
    <tr>
        <td>
        분석 계획서 마감
        </td>
        <td>
        2021.06.04
        </td>
        <td>
        온라인 접수
        </td>
    </tr>
    <tr>
        <td>
        서류 통과자 발표(3배수) 및 분석 계획 발표 준비
        </td>
        <td>
        -
        </td>
        <td>
        -
        </td>
    </tr>
    <tr>
        <td>
        분석 계획 발표
        </td>
        <td>
        2021.07.27
        </td>
        <td>
        SW융합테크비즈센터
        </td>
    </tr>
    <tr>
        <td>
        발표 통과자 발표(2배수) 및 분석 진행
        </td>
        <td>
        -
        </td>
        <td>
        -
        </td>
    </tr>
    <tr>
        <td>
        분석 결과 발표
        </td>
        <td>
        2021.09.27
        </td>
        <td>
        SW융합테크비즈센터
        </td>
    </tr>
    <tr>
        <td>
        시상식
        </td>
        <td>
        2021.10.14
        </td>
        <td>
        대구은행 본점
        </td>
    </tr>
</table>

대회의 일정은 위와 같았다.

<br>

<!---

## 나의 일정
사담이 많이 포함되어 있습니다.
<details>
<summary>접기/펼치기</summary>
<div markdown="1">

 - 6월

    1학기 막바지. 기말고사 기간이 시작되기 직전에 계획서를 작성하였었다.

    주제를 무엇을 해야하나.. 팀원 셋이 오래 고민을 했던 기억이 남아 있다.

    좋은 주제를 잡아 6월 초에 완성하였고, 남은 6월은 기말고사와 [졸업 프로젝트](https://github.com/SNMHZ/Drug_Recommendation) 한학기 마무리, [CLOVA AI RUSH](https://campaign.naver.com/clova_airush/)와 [동아리 프로젝트(이건 망해버렸다..ㅠㅠ)](https://github.com/SNMHZ/KNUDART_8TH)를 진행하며 정신없이 지냈다.

    이제 보니 이건 어째 시간투자 제일 적게한 기말고사만 좋은 결과가 나온 것 같다..;

 - 7월

    경상북도 경산에 위치한 [SL](http://www.slworld.com/)로 한달간 현장실습을 다녀왔다.

    현장 실습 기간 내에 분석 계획 발표가 잡혀서, [SL에서 진행했던 프로젝트](https://github.com/hyedinion/DrivePosition)를 거의 마무리하고, 현장실습생들을 관리해주신 책임님께 양해(책임님... 저 화요일에 발표가 있는데... 오전에 발표하고 출근해도 될까요...?)를 구하고 현장실습생에게 원래는 없는 반차(!)를 썼던 기억이 난다.

    정말.. 다시 생각해도 이걸 다 배려해준 우리 대구빅데 친구들, 그리고 같이 현장실습 갔던 친구들, 마지막으로 흔쾌히 해결해 주신 책임님까지 모두에게 감사한 마음 뿐이다.

    그리고 현장실습 마지막날, 7월 30일에는 코로나19 백신을 맞았다. 그 이유는...

 - 8월

    웃기게도 나란 인간은 8월에 서울에서 일정을 잡아버린 것이다.

    당시에 수도권에 코로나가 막 확산하던 시기었기에 맞고 올라가면 좋을 것 같다는 판단이었다.

    서울에서 잡은 일정은 [데이터 청년 캠퍼스(2021)](https://dataonair.or.kr/bigjob/)라는 프로그램이었다.

    내가 주도적으로 찾아서 신청했던 것은 아니었고, 기말고사가 끝날 때 쯤 지도교수님께서 권유해 주신 덕분에 참여할 수 있었다.

    사실, 원래 계획은 8월에는 대구빅데에 집중하며 영어 성적 취득 및 알고리즘 문제 풀면서 코딩테스트 감을 끌어올릴 생각이었다.

    하지만 데이터 청년 캠퍼스 1등상이 무려 장관상(!)이기에 욕심이 나서 참여하는거로 계획을 크게 수정했다.

    아쉽게도 [데청캠 프로젝트](https://github.com/SNMHZ/LocationAnalysis_ReverseVendingMachine_Seoul)는 동국대학교 3위로 마무리 했다.

    데청캠 이야기도 참 할말이 많지만 디테일은 각설하고, 대구빅데로 돌아오겠다.

    대구빅데와 데청캠 일정이 충돌해 버리는 문제가 있었으니, 데청캠 팀원들이 8월 2일부터 만나서 프로젝트를 진행하기로 한 것이었다.

    그런데 대구빅데 분석 계획 통과자 발표가 8월 2일이었기에, 우리는 이때까지 분석 이렇게 할거에요! 만 있고 정작 실 데이터는 구경도 못한 상황이었다...ㅋㅋㅋㅋ

    다른 대구빅데 팀원들도 7월 말부터 현장실습을 간 상황. 실 데이터를 확인하러 갈 사람은 나밖에 없었다.

    결국 나는 8월 2일 대구 빅데이터 분석실에서 데청캠 프로젝트에 온라인으로 참여하며(얘네들은 이날 동국대에서 직접 처음 만남), 열심히 전처리하고 정리해서 반출 신청을 하려고 했다.

    하지만 분석실 담당자님이 퇴근하시고 나서 내 작업이 끝난 바람에, 다음날 오전에 와서 반출하고, 그길로 서울로 올라갔다.

    실 데이터에서 당연하게도(!) 문제가 발생했다.

    어느 정도 부실할 것이라 예상은 했지만, 우리의 기대에 크게 못 미칠 정도였다.

    그래서 우린 게더타운으로 이걸 어떻게 해야할지를 계속 회의했었다.

    주제를 엎어야 하나.. 틀어야 하나.. 같은 얘기도 할 정도로 한달동안은 거의 이에 대해 고민했었다.

    결론은 본래 계획대로 진행이었다.

    데이터가 조금 부실해도 어떻게든 맞출 수 있을 것 같은 방법을 짜내는데 성공했기에, 계획대로 밀어붙이기로 했다.

    데청캠 프로젝트는 PPT 제작만 남겨두고 대구빅데 작업에 조금이라도 더 시간을 투자하는게 맞을 것 같아 8월 말 대구로 내려왔다.

    그리고 데청캠 PPT 작업은 주말에 온라인으로 밤샘 했다..

    내 욕심때문에 고생한 데청캠 친구에게도 너무 고맙다.

 - 9월

    그리고 개강 후, 대구빅데 분석을 마무리 하면서도 문제가 하나 발생했다.

    우리의 분석은 크게 라벨링과 모델링, 두가지로 볼 수 있다.

    라벨링 시 우리가 생성한 시계열 데이터를 사용하는데, 도무지 시계열 데이터의 정상성을 보장할 수 없는 점이었다.

    이 부분 해결을 위해 다른 방법 생각하고, 구현, 모델링하느라 추가적인 시간이 소모되었다.

    그리고 보고서와 발표자료 만들고, 졸프 2학기 계획서 만들고, 기업들 지원서도 작성 등등.. 꽤나 바빴던 것 같다.

    그리고 9월 27일, 분석자료 발표 후 예상치 못한 인터뷰 영상을 찍었다.

    그리고 나는 인터뷰에서 헛소리를...했다.

 - 10월

    시상식만 남았다.

    시상식 때 인터뷰 영상을 틀어주었다.

    내가 헛소리하는거 보기 부끄러워 정말 2주 내내 앓고 있었는데, 감사하게도 편집해 주셨다.ㅋㅋㅋㅋ

    그리고 일찍 수상자에게는 언질이라도 주지 않을까 했는데, 시상하는 그 순간까지도 누가 수상자인지 알려주지 않았다.

<center><img src="../assets/image/storys/dg_bigdata/시상식1.png" width="70%"></center>

</div>
</details>

--->

<br>

# 분석 내용

## 주제 요약
<img src="/image/story/dg_bigdata/slide1.png" width="70%"><br><sup>(디자인 정말 이쁘다!!)</sup><br>

> 딥러닝을 통해 경제변수 변화에 따른 금융시장 참여자의 행동 변화를 예측·분석하여 초개인화된 금융상품과 서비스를 추천 및 개발할 수 있도록 한다

우리가 분석 목적으로 적어 놓은 문장.

거창하게 요약하긴 했지만, 실제로는 복잡하지 않다.

핵심은 `경제 변수(환율, 금리 등)에 민감한 사람을 라벨링` 하고, `이를 예측`하는 것. 두가지로 나누어 볼 수 있다.

<br>

## 계획과 구현의 변경점
실 데이터를 보기 전 분석 계획서가 통과되어야 실 데이터를 만질 수 있다.

데이터 설명서만 보고 기대한 것과, 실 데이터 사이 간극이 존재하다 보니 방법에서 약간의 변경점이 있었다.
 - [(실데이터 보기 전)분석 계획서](https://nbviewer.org/github/SNMHZ/Personal_Macroeconomic_Sensitivity/blob/master/documents/%EA%B3%BC%EC%A0%9C%EB%B6%84%EC%84%9D%EA%B3%84%ED%9A%8D%EC%84%9C_GoDart.pdf)
 - [(실데이터 보기 전)분석 계획 발표자료](https://nbviewer.org/github/SNMHZ/Personal_Macroeconomic_Sensitivity/blob/master/documents/1%EC%B0%A8%EB%B0%9C%ED%91%9C%EC%9E%90%EB%A3%8C_GoDart.pdf)
 - [(분석 완료)분석 보고서](https://nbviewer.org/github/SNMHZ/Personal_Macroeconomic_Sensitivity/blob/master/documents/%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C_%EB%B6%84%EC%84%9D%EB%B3%B4%EA%B3%A0%EC%84%9C_GoDart.pdf)
 - [(분석 완료)분석 결과 발표자료](https://nbviewer.org/github/SNMHZ/Personal_Macroeconomic_Sensitivity/blob/master/documents/%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C_%EB%B0%9C%ED%91%9C%EC%9E%90%EB%A3%8C_GoDart.pdf)

방법을 약간 바꾼 가장 큰 이유는 데이터에 대한 우리 기대가 너무 컸다는 점이다.

예로, 우리는 데이터 기간이 `2018.01 ~ 2019.12`이기에 매달의 존재할 것으로 기대했다.

하지만 실제로는 단 3시점의 데이터만 있었기에 기준 시점으로 2달 전까지의 데이터를 생성하여 활용하였다.

<img src="/image/story/dg_bigdata/이상과현실.png" width="100%">

여기 표가 다 채워져 있기를 바랐었다.

<img src="/image/story/dg_bigdata/slide10.png" width="70%">

그래서 `그랜저 인과관계 검정` 대신 `상관관계`를 통해 민감 고객 분류를 시도한 점이 가장 큰 변경점이다.

## 발표 중 받았던 일부 질문
1. __train/test set을 다 합쳐서 7:3 하지 않고 왜 19,20/21로 나누었는가?__

    <img src="/image/story/dg_bigdata/slide14.png" width="70%"><br>
    미래참조 문제 때문인데, 7:3으로 나누면 왜 안되는지를 위주로 답변하였다.
     - 모델이 21년 샘플로 학습하고, 19년 샘플로 검증을 시도할 가능성이 생긴다.
     - 이 경우, 19년 시점에선 절대 알 수 없는 데이터로 검증이 이루어진 셈이다. 
     - 위의 경우, 결과가 왜곡될 수 있으므로 피하는 것이 좋다.

2. __예측하는데 있어 따로 pre trained model은 활용하지 않았는가?__

    <img src="/image/story/dg_bigdata/slide16.png" width="70%"><br>
    pre trained model. 딥러닝, 특히 자연어 처리와 이미지 처리에서 매우 중요한 개념이 아닐 수 없다.
    
    근래 자연어 처리 프로젝트를 진행하며 BERT를 접해볼 기회가 있었다.

    이에 깊게 파고든 것은 아니었지만, 써먹기 위해 대략적인 개념에 대해 찾아보았었다.

    그리고 내가 이번 공모전을 준비하며 했던 생각은, `BERT정도는 아니어도 대구은행 고객 데이터로 어느정도 유의미한 User Embedding을 만들어 활용할 수 있지 않을까?` 하는 욕심이었다.

    물론 위 질문에 대한 답변은 `대구은행 고객데이터와 같은 형식의 input을 활용해 금융데이터를 학습시킨 pre trained 모델은 없기 때문에, 초기화된 모델의 weight들을 직접 학습시켰다`고 답변했다.

    내가 조금 더 공부하고, 시간이 넉넉하여 활용 가능성에 대한 검증까지 진행했다면, 내 욕심까지 덧붙여서 센스 있는 답변까지 가능했을지도 모르겠다.

    하지만, 아직도 내 욕심에 대한 답변은 못 내겠다. 

    난 소프트웨어 전공이고, 아직은 겉핥기로 통계를 만져봤을 뿐이기에, 확신이 없는 것 같다.

    사실 난 그저 개발이 재미있고, 모델링은 알고리즘만으로 해결하기 힘든 문제를 해결해 주기에 재미있게 느꼈던 것이 아닌가 싶은 생각도 한다.

    개발을 좋아하지만, 빅 데이터 시대에 개발과 통계의 유착관계(?)는 점점 더 심해지지 않을까. 

    그렇다면 더 공부를 하면 이 욕심에 대한 내 스스로 마음에 드는 답변을 할 수 있지 않을까 기대해 본다.

3. __시계열 데이터는 계절성을 가질 가능성이 높은데, 이는 어떻게 처리하였나?__

    위의 슬라이드와 어느정도 이어진다.

    이에 대한 답변은 내가 `19년 12월, 20년 12월 시점 데이터로 학습한 모델을 21년 4월 시점으로 검증하였으니 크게 문제되지 않을 것이다` 
    
    라고 한 것을 같이 발표 갔던 친구가 받아서, `input으로 해당 시점의 경제변수 시계열 데이터도 함께 넣어 주어 모델이 계절성에 대응할 수 있도록 했다`고 정정해 주었다.

    이 질문을 받고선, 내 통계 실력은 정말 겉핥기 수준밖에 안되는구나! 싶을 정도로 뒤통수를 쎄게 얻어맞은 듯한 느낌이었다.

    '계절성' 이란 것을 알고는 있었는데, 내게 모델링을 할 때 있어 계절성은 전혀 고려하지 않은 개념이었기 때문이다.

    input으로 해당 시점의 경제변수 시계열 데이터도 함께 넣는 것이 내가 낸 아이디어이긴 했지만, 나는 input이 너무 부족한 상황에서 그 상황을 표현할 수 있는 정보를 더 추가하려는 취지였기 때문이다.

    내게 있어 그건 그저 모델 성능을 높이기 위한 추가적인 데이터에 지나지 않았었다. 그래서 중요하지 않게 생각했고, 모델 구조 그림에서도 따로 표현하지 않고 생략으로 대체했다.

    그저 LSTM에 다 때려넣는다고 답이 나오는게 아닌데.. 통계가 전공인 그 친구는 내 말을 듣고 계절성부터 떠올리지 않았었을까?

    시계열 공부 할 필요성도 크게 느꼈고, 더 많은 경험이 필요하겠다 싶었다. ~~언제쯤 할 수 있을지는 잘 모르겠지만..~~

<br>

## 내가 아쉬웠던 사항

### 모델 활용 방안에서의 디테일

우리의 주제는 `초 개인화 서비스 제안`으로 딱 박혀 있는데 정작 이 부분은 너무 부실하다.

<img src="/image/story/dg_bigdata/slide23.png" width="70%"><br>
<img src="/image/story/dg_bigdata/slide24.png" width="70%"><br>
정교한 데이터 분석 및 예측은 앞단인 `라벨링`과 `모델링`에만 집중되어 있고, 활용인 `제안`부분은 그냥 모델이 예측한 것의 정성적인 활용 방안에 불과하다.

약간의 변명을 해 보자면

일단 앞단이 되어야 다음 단계가 진행이 되는데, `라벨링` 과정에서도 데이터가 우리 예상과 달라 다른 해결 방안을 고안하느라 진행이 더뎠다. 

`모델링`에서도 input으로 이걸 활용해도 되는지, 논리적으로 문제는 없는지, 불균형한 데이터셋 처리와 같은 디테일에 대한 고민은 물론, 코딩하며 무수한 OOM과도 만나게 되다 보니 빠르게 진행하지 못했다.

무엇보다 나는 그저 모델의 성능을 어떻게든 더 높일 방안만 생각하고 있었고  `제안`을 고민해야 한다는 사실은 전혀 내 머릿속에 없었다.

이건 '딥러닝'을 활용해 보고 싶었던 내 욕심이 너무 반영되어 버린 결과가 아닌가 싶다.

텐서플로우로 MLP만 만들어 보았었는데, CLOVA AI RUSH를 거치며 토치로 신경망을 자유롭게 만드는 방법을 막 인힌 상황에 몸이 달아서, 이걸로 신경망 모델링을 해보고 싶었던 욕심이 너무 컸던 것 같다.

다시말해, '신경망 구조를 이렇게 하면 모델 성능이 개선 될 것이고 실제로 더 좋다!' 같은 모델링 챌린지 마인드였다. 공모전의 목표를 보았어야 하는데..

팀의 SW 전공자인 내가 이러고 있으니 진행이 잘 될리가 있나.. 이는 팀원들에게 매우 미안한 부분으로 남아있다.

<br>

### 발표 자료 준비에서의 디테일

<img src="/image/story/dg_bigdata/slide11.png" width="70%"><br>
<img src="/image/story/dg_bigdata/slide20.png" width="70%"><br>
분석 결과 발표 시 예시를 들 때 고용률을 활용하였다.

고용률은 우리가 임의로 1달 lagging하여 사용하였다 보니, 분석 방법과 활용 방안에서의 이미지를 잘 보면 상관관계가 거꾸로 뒤집혀 있다. 

__그리고 PPT에 이에 대한 설명이 아예 없었다.__

왜 이렇게 했나? 어쩌면 당연히 들어갔어야 할 부분인데 보고서랑 발표자료 후다닥 만들어 낸다고 미처 챙기지 못한 부분 같다.

고용률에 대해서만 1달 lagging 한 이유는 정량적이라기 보단 정성적인 이유에 가깝다.

정성적인 이유라지만 나름의 논리는 있었다.

먼저, 우리의 원래 계획으로는 그랜저 인과관계 검정을 활용하는 것이었기에 정상 시계열임을 확인하기 전 일단 그랜저 인과관계 검정을 시도해 봤었다.

그랜저 인과검정은 시차(lags)를 주어 두 시계열의 인과관계를 검정할 수 있으며, 적정한 시차를 찾아내는 것 역시 중요하다.

그리고 이 시차는 과거 n달 전의 사건이 영향을 끼친다 라고 할 수 있다.

우리는 가능한 여러 시차를 주어(많이는 못했다. 시계열이 짧았기 때문) 검정을 해 봤고, 고용률은 가장 설명력이 좋은(p-value가 가장 작은) 시차가 1달이었던 것으로 기억한다.

이후 그랜저 인과검정의 선행요건이 정상 시계열을 만족해야 함을 확인하고, 우리의 대부분의 시계열이 이를 만족하지 않았기에 이 자료는 내가 따로 기록하지 않았다..

또한, 논리를 생각해 봤을때, 고용률은 월급과 관계 있을 것 같다는 1차원적인 상상을 했는데, 그렇다면 한달 lagging 하는게 맞지 않나? 라는 생각을 했다.

또한 상관관계도 한달 lagging한 상관관계는 설명이 너무 잘되는데 lagging 하기 전의 상관관계는 도무지 설명되지 않았던 이유도 있다.

이런 나름의 논리는 있었지만 결국은 정성적이다 보니 어쩌면 무의식적으로, 정성적 기준을 도입했다는 이유 때문에 이 부분을 생각하는 것에 거부감이 들었을지도 모르겠다.

이를 증명이라도 하듯 모든 것이 담겨 있어야 할 __보고서에도 1달 시차 주었다 한줄만__ 달랑 들어가 있고 왜 그랬는지에 대한 __이유는 아예 없다__.

<img src="/image/story/dg_bigdata/뼈아픈실책.png" width="100%"><br>
<sup>다 잘해놓고..</sup>

왜 그렇게 했나에 대한 집착은 또 하고 또 해도 부족하지 않나. 결국 이게 어떤 프로젝트를 진행해도 퀄리티(품질)의 핵심이 아닌가.

그리고 이것을 다시 봐도 바로 내가 이해하도록, 다른 사람도 이해하도록 잘 만들어야 하는데, 이건 너무 큰 실책이었다.

장려상에서 그친 것도 이 부분을 논리적으로 설명하지 못한 것이 너무 크지 않았나.. 나는 그렇게 생각이 든다.

<br>

### 발표 중에서의 디테일

이건 발표 태도의 문제에 가까운 것 같은데, 발표를 하면서 중간중간 청중(심사위원)분들과 아이컨택도 하며 반응 봐가며 진행을 했어야 하는데 그러질 못했다.

일단 많은 내용을 다 담으려다 보니 열심히 말만 해야 겨우 10분 내외로 들어오는 분량의 스크립트였기에 이걸 어떻게든 10분 안에 다 말해야 한다는 압박이 있었던 것 같다.

또한 이것은 어투의 문제에 가까운데, 질문에 답변할 때 너무 단호하게 대답하는 경향이 있었다..

그냥 유들유들하게 대답하면 되는 문제인데 쓸데없이 각 세워서 전달하는 느낌.. 너무 긴장해서 그런건가.. 왜이러니.. 내가 말하면서도 깜짝 놀랐었다.

그리고 위의 고용률 관련 질문을 받고는 가장 약한 부분을 받고 멘탈이 반쯤 깨져서 어버버버.. 하면서 다음 질문들 답변한 기분인데 같이 발표 갔던 친구가 잘 수습해 준 덕분에 잘 마무리 하고 나올 수 있었다. 

발표도 나에겐 아직 더 많은 경험이 필요할 듯 싶다..

<br>

# 대회를 마치고

가장 먼저, 같이 해준 팀원 친구들에게 너무 고맙다.

'딥러닝을 통해'역시 우리의 목표 중 하나였지만 저 상황에서 제일 성능 좋은 모델은 랜덤 포레스트였다. 

모델링 경험치도 부족하고, 데이터도 부족하고 하다 보니 발생한 상황인데 오히려 전화위복이라고 feature importance를 끌고 와서 활용 방안으로 넣어버렸다.

다만 딥러닝 모델은 '시계열 길이를 늘리면 딥러닝이 더 성능이 좋아질 것이다'로 마무리하고 데이터가 부족해 증명하지 못한 것은 약간 아쉽다.

어떤 프로젝트를 끝내고도 하는 생각이지만, 내가 좀 더 열심히 했으면.. 미리 비슷한 프로젝트를 해봤으면.. 발표 경험이 좀 있었으면.. 이번 프로젝트를 더 완벽하게 끝내지 않았을까 싶은 생각이 든다.

있을 수 없는 일이지만 이런 아쉬운 생각은 항상 드는 듯 하다..

그렇지만 이렇게 모두 다른 전공 셋이 모여 하나만 바라보고 달려서 혼자서는 절대 못해낼 프로젝트를 완료하고, 수상까지 했다는 데에서 너무 만족스럽다.

또한 AI RUSH 이후로도 느꼈던 것이지만 모델링에 석사 이상을 선호하는 이유도 확실하게 느낄 수 있었다.

아무래도 학사는 이런 일련의 과정들에 대해 경험치가 부족할 가능성이 높을 수 밖에 없지 않나..

그래도 계속 공부해나가면 백엔드부터 모델링까지 아우를 수 있는 개발자가 될 수 있지 않을까?

최종 결과는 장려상이다.

<img src="/image/story/dg_bigdata/시상식2.png" width="70%">

우리 팀장님이 서울로 인턴을 가버려서 저 자리는 내가 갔다.

<img src="/image/story/dg_bigdata/상장.png" width="70%">

<!-- ~~과연 우리의 회식은 이루어 질 수 있을지..?ㅋㅋ~~ -->
<!--아마도 없을 듯.--> 